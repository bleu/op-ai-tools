{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import zlib\n",
    "import asyncpg\n",
    "import psycopg2\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "random_seed = 42\n",
    "\n",
    "## temporary open source embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## openai api key\n",
    "openai_api_key = input(\"Enter the OpenAI API key: \")\n",
    "model_embeddings = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental dataset updates PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data\n",
    "\n",
    "test_dataset = pd.read_csv('../002_create_test_dataset/001_questions_per_section/cleaned_test_dataset_with_clusters.csv')    ### placeholder data\n",
    "initial_dataset = test_dataset[['question', 'answer']].iloc[:10] ### first 10 rows\n",
    "late_dataset = test_dataset[['question', 'answer']].iloc[10:15]  ### rows 11 to 15\n",
    "v2_dataset = test_dataset[['question', 'answer']].iloc[:15]      ### first 15 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76568896e-02  6.34958372e-02  4.87130992e-02  7.93049559e-02\n",
      "   3.74480002e-02  2.65277550e-03  3.93748470e-02 -7.09843775e-03\n",
      "   5.93614727e-02  3.15369666e-02  6.00980483e-02 -5.29051460e-02\n",
      "   4.06067446e-02 -2.59308070e-02  2.98427530e-02  1.12692360e-03\n",
      "   7.35149309e-02 -5.03819771e-02 -1.22386597e-01  2.37028338e-02\n",
      "   2.97265388e-02  4.24768552e-02  2.56337505e-02  1.99520006e-03\n",
      "  -5.69190979e-02 -2.71598492e-02 -3.29035781e-02  6.60248548e-02\n",
      "   1.19007118e-01 -4.58791591e-02 -7.26215392e-02 -3.25839818e-02\n",
      "   5.23414165e-02  4.50552553e-02  8.25298391e-03  3.67023274e-02\n",
      "  -1.39415376e-02  6.53919727e-02 -2.64272522e-02  2.06360957e-04\n",
      "  -1.36643481e-02 -3.62809449e-02 -1.95042938e-02 -2.89738737e-02\n",
      "   3.94270606e-02 -8.84090737e-02  2.62422441e-03  1.36714354e-02\n",
      "   4.83063050e-02 -3.11565213e-02 -1.17329143e-01 -5.11690415e-02\n",
      "  -8.85287598e-02 -2.18961649e-02  1.42986402e-02  4.44168150e-02\n",
      "  -1.34814540e-02  7.43392408e-02  2.66382471e-02 -1.98762249e-02\n",
      "   1.79190598e-02 -1.06052896e-02 -9.04263407e-02  2.13269144e-02\n",
      "   1.41204879e-01 -6.47170516e-03 -1.40382291e-03 -1.53609905e-02\n",
      "  -8.73571411e-02  7.22173750e-02  2.01403070e-02  4.25587371e-02\n",
      "  -3.49014178e-02  3.19670653e-04 -8.02970305e-02 -3.27472128e-02\n",
      "   2.85268258e-02 -5.13658449e-02  1.09389216e-01  8.19328204e-02\n",
      "  -9.84039083e-02 -9.34094563e-02 -1.51291899e-02  4.51248065e-02\n",
      "   4.94171940e-02 -2.51868013e-02  1.57077331e-02 -1.29290655e-01\n",
      "   5.31895459e-03  4.02345089e-03 -2.34572776e-02 -6.72983453e-02\n",
      "   2.92280875e-02 -2.60845087e-02  1.30624715e-02 -3.11663672e-02\n",
      "  -4.82713655e-02 -5.58859818e-02 -3.87505628e-02  1.20010823e-01\n",
      "  -1.03924619e-02  4.89704795e-02  5.53537533e-02  4.49359417e-02\n",
      "  -4.00964124e-03 -1.02959730e-01 -2.92968638e-02 -5.83401769e-02\n",
      "   2.70472430e-02 -2.20169388e-02 -7.22241849e-02 -4.13868614e-02\n",
      "  -1.93297677e-02  2.73329299e-03  2.76950246e-04 -9.67587680e-02\n",
      "  -1.00574732e-01 -1.41922850e-02 -8.07891265e-02  4.53925207e-02\n",
      "   2.45040357e-02  5.97613454e-02 -7.38185644e-02  1.19843995e-02\n",
      "  -6.63403273e-02 -7.69044682e-02  3.85156758e-02 -5.59362146e-33\n",
      "   2.80013215e-02 -5.60784712e-02 -4.86601591e-02  2.15569772e-02\n",
      "   6.01980202e-02 -4.81403396e-02 -3.50247137e-02  1.93313826e-02\n",
      "  -1.75151788e-02 -3.89210433e-02 -3.81064788e-03 -1.70287602e-02\n",
      "   2.82099806e-02  1.28290206e-02  4.71601225e-02  6.21029027e-02\n",
      "  -6.43588826e-02  1.29285663e-01 -1.31230950e-02  5.23069277e-02\n",
      "  -3.73680778e-02  2.89094243e-02 -1.68980546e-02 -2.37329789e-02\n",
      "  -3.33491564e-02 -5.16762920e-02  1.55356703e-02  2.08803546e-02\n",
      "  -1.25371059e-02  4.59579118e-02  3.72720845e-02  2.80566718e-02\n",
      "  -5.90005368e-02 -1.16988542e-02  4.92181964e-02  4.70328592e-02\n",
      "   7.35487342e-02 -3.70529778e-02  3.98457050e-03  1.06411902e-02\n",
      "  -1.61625387e-04 -5.27166128e-02  2.75927559e-02 -3.92921641e-02\n",
      "   8.44718143e-02  4.86860648e-02 -4.85873362e-03  1.79948397e-02\n",
      "  -4.28569540e-02  1.23375040e-02  6.39951881e-03  4.04822566e-02\n",
      "   1.48887504e-02 -1.53941708e-02  7.62947425e-02  2.37044040e-02\n",
      "   4.45237458e-02  5.08194566e-02 -2.31257151e-03 -1.88737176e-02\n",
      "  -1.23335738e-02  4.66002524e-02 -5.63438311e-02  6.29926994e-02\n",
      "  -3.15534882e-02  3.24912407e-02  2.34672967e-02 -6.55437410e-02\n",
      "   2.01708842e-02  2.57082321e-02 -1.23868212e-02 -8.36505648e-03\n",
      "  -6.64377734e-02  9.43074077e-02 -3.57092321e-02 -3.42483222e-02\n",
      "  -6.66352268e-03 -8.01525079e-03 -3.09711527e-02  4.33012433e-02\n",
      "  -8.21398385e-03 -1.50795028e-01  3.07692345e-02  4.00718376e-02\n",
      "  -3.79294008e-02  1.93206372e-03  4.00530659e-02 -8.77074301e-02\n",
      "  -3.68492082e-02  8.57948791e-03 -3.19251493e-02 -1.25257932e-02\n",
      "   7.35538825e-02  1.34740188e-03  2.05919389e-02  2.71098091e-33\n",
      "  -5.18576615e-02  5.78360371e-02 -9.18985605e-02  3.94422114e-02\n",
      "   1.05576493e-01 -1.96912196e-02  6.18402995e-02 -7.63464496e-02\n",
      "   2.40880270e-02  9.40049440e-02 -1.16535529e-01  3.71198691e-02\n",
      "   5.22424914e-02 -3.95853864e-03  5.72214536e-02  5.32851089e-03\n",
      "   1.24016769e-01  1.39022898e-02 -1.10249240e-02  3.56053077e-02\n",
      "  -3.30754593e-02  8.16573426e-02 -1.52003830e-02  6.05585165e-02\n",
      "  -6.01397268e-02  3.26102786e-02 -3.48296128e-02 -1.69881955e-02\n",
      "  -9.74907875e-02 -2.71483250e-02  1.74707873e-03 -7.68982098e-02\n",
      "  -4.31858450e-02 -1.89985391e-02 -2.91661508e-02  5.77488095e-02\n",
      "   2.41821557e-02 -1.16901556e-02 -6.21435158e-02  2.84351483e-02\n",
      "  -2.37517248e-04 -2.51783114e-02  4.39633382e-03  8.12840685e-02\n",
      "   3.64184268e-02 -6.04006238e-02 -3.65518257e-02 -7.93748125e-02\n",
      "  -5.08527830e-03  6.69699311e-02 -1.17784277e-01  3.23744118e-02\n",
      "  -4.71251942e-02 -1.34460125e-02 -9.48445424e-02  8.24945141e-03\n",
      "  -1.06748864e-02 -6.81881905e-02  1.11820863e-03  2.48019323e-02\n",
      "  -6.35889322e-02  2.84492429e-02 -2.61303429e-02  8.58111531e-02\n",
      "   1.14682265e-01 -5.35345450e-02 -5.63588217e-02  4.26008590e-02\n",
      "   1.09454198e-02  2.09578741e-02  1.00131206e-01  3.26051898e-02\n",
      "  -1.84208795e-01 -3.93208191e-02 -6.91454336e-02 -6.38105869e-02\n",
      "  -6.56385720e-02 -6.41255360e-03 -4.79613096e-02 -7.68133849e-02\n",
      "   2.95384694e-02 -2.29948647e-02  4.17036638e-02 -2.50046998e-02\n",
      "  -4.54504276e-03 -4.17136513e-02 -1.32289436e-02 -6.38357773e-02\n",
      "  -2.46472051e-03 -1.37337716e-02  1.68976001e-02 -6.30397871e-02\n",
      "   8.98880586e-02  4.18170504e-02 -1.85687486e-02 -1.80442168e-08\n",
      "  -1.67998280e-02 -3.21577787e-02  6.30384386e-02 -4.13092524e-02\n",
      "   4.44819778e-02  2.02471530e-03  6.29592538e-02 -5.17370133e-03\n",
      "  -1.00443903e-02 -3.05640865e-02  3.52672301e-02  5.58581986e-02\n",
      "  -4.67124991e-02  3.45102213e-02  3.29578072e-02  4.30114716e-02\n",
      "   2.94361655e-02 -3.03164497e-02 -1.71107482e-02  7.37485215e-02\n",
      "  -5.47910035e-02  2.77515836e-02  6.20163465e-03  1.58800669e-02\n",
      "   3.42978686e-02 -5.15754707e-03  2.35079695e-02  7.53135607e-02\n",
      "   1.92843247e-02  3.36196460e-02  5.09103462e-02  1.52497038e-01\n",
      "   1.64207555e-02  2.70528086e-02  3.75163145e-02  2.18554046e-02\n",
      "   5.66333421e-02 -3.95747647e-02  7.12313503e-02 -5.41377142e-02\n",
      "   1.03780290e-03  2.11853292e-02 -3.56308408e-02  1.09017000e-01\n",
      "   2.76528951e-03  3.13996822e-02  1.38422474e-03 -3.45737897e-02\n",
      "  -4.59277891e-02  2.88083777e-02  7.16911908e-03  4.84684967e-02\n",
      "   2.61018686e-02 -9.44073964e-03  2.82169562e-02  3.48723494e-02\n",
      "   3.69098373e-02 -8.58945865e-03 -3.53205688e-02 -2.47856621e-02\n",
      "  -1.91921256e-02  3.80707830e-02  5.99653833e-02 -4.22287025e-02]\n",
      " [ 8.64385664e-02  1.02762632e-01  5.39451465e-03  2.04440113e-03\n",
      "  -9.96338855e-03  2.53855549e-02  4.92875502e-02 -3.06265745e-02\n",
      "   6.87254667e-02  1.01366043e-02  7.75397792e-02 -9.00806785e-02\n",
      "   6.10614009e-03 -5.69898672e-02  1.41715044e-02  2.80491635e-02\n",
      "  -8.68464485e-02  7.64399320e-02 -1.03491247e-01 -6.77438155e-02\n",
      "   6.99947178e-02  8.44251290e-02 -7.24916114e-03  1.04770092e-02\n",
      "   1.34020941e-02  6.77576736e-02 -9.42086428e-02 -3.71689834e-02\n",
      "   5.22617698e-02 -3.10853533e-02 -9.63406637e-02  1.57716833e-02\n",
      "   2.57866848e-02  7.85245225e-02  7.89949149e-02  1.91516597e-02\n",
      "   1.64357089e-02  3.10085318e-03  3.81311625e-02  2.37090979e-02\n",
      "   1.05389347e-02 -4.40644696e-02  4.41738404e-02 -2.58727502e-02\n",
      "   6.15378544e-02 -4.05427888e-02 -8.64140615e-02  3.19723003e-02\n",
      "  -8.90714873e-04 -2.44437251e-02 -9.19721276e-02  2.33939718e-02\n",
      "  -8.30293521e-02  4.41510789e-02 -2.49693096e-02  6.23020642e-02\n",
      "  -1.30350690e-03  7.51395375e-02  2.46384945e-02 -6.47244304e-02\n",
      "  -1.17727824e-01  3.83391976e-02 -9.11767855e-02  6.35446310e-02\n",
      "   7.62739554e-02 -8.80241022e-02  9.54558980e-03 -4.69717346e-02\n",
      "  -8.41740295e-02  3.88823673e-02 -1.14393570e-01  6.28854614e-03\n",
      "  -3.49361449e-02  2.39750613e-02 -3.31316814e-02 -1.57244168e-02\n",
      "  -3.78955640e-02 -8.81248340e-03  7.06119016e-02  3.28066386e-02\n",
      "   2.03670980e-03 -1.12278916e-01  6.79724105e-03  1.22765340e-02\n",
      "   3.35303359e-02 -1.36200441e-02 -2.25490183e-02 -2.25228667e-02\n",
      "  -2.03193985e-02  5.04297465e-02 -7.48653114e-02 -8.22822452e-02\n",
      "   7.65962601e-02  4.93392088e-02 -3.75553593e-02  1.44634340e-02\n",
      "  -5.72457500e-02 -1.79954618e-02  1.09697953e-01  1.19462766e-01\n",
      "   8.09195742e-04  6.17057458e-02  3.26322503e-02 -1.30780146e-01\n",
      "  -1.48636580e-01 -6.16232865e-02  4.33885902e-02  2.67128944e-02\n",
      "   1.39786173e-02 -3.94002497e-02 -2.52711289e-02  3.87740252e-03\n",
      "   3.58664468e-02 -6.15420379e-02  3.76660675e-02  2.67565046e-02\n",
      "  -3.82659398e-02 -3.54793295e-02 -2.39227228e-02  8.67977366e-02\n",
      "  -1.84063055e-02  7.71039352e-02  1.39864197e-03  7.00382963e-02\n",
      "  -4.77878004e-02 -7.89819732e-02  5.10813929e-02 -2.99868425e-33\n",
      "  -3.91646363e-02 -2.56214431e-03  1.65210422e-02  9.48938914e-03\n",
      "  -5.66219203e-02  6.57783076e-02 -4.77002598e-02  1.11661498e-02\n",
      "  -5.73558398e-02 -9.16255265e-03 -2.17521135e-02 -5.59531525e-02\n",
      "  -1.11422818e-02  9.32793915e-02  1.66765060e-02 -1.36723500e-02\n",
      "   4.34388295e-02  1.87247468e-03  7.29946606e-03  5.16332127e-02\n",
      "   4.80608530e-02  1.35341480e-01 -1.71739124e-02 -1.29698226e-02\n",
      "  -7.50109106e-02  2.61107516e-02  2.69801915e-02  7.83029594e-04\n",
      "  -4.87270355e-02  1.17842816e-02 -4.59580347e-02 -4.83213700e-02\n",
      "  -1.95670780e-02  1.93889271e-02  1.98807362e-02  1.67432297e-02\n",
      "   9.87801254e-02 -2.74087973e-02  2.34809201e-02  3.70234787e-03\n",
      "  -6.14514574e-02 -1.21231889e-03 -9.50472616e-03  9.25156567e-03\n",
      "   2.38443706e-02  8.61231759e-02  2.26790048e-02  5.45116840e-04\n",
      "   3.47130075e-02  6.25464320e-03 -6.92771561e-03  3.92400585e-02\n",
      "   1.15674781e-02  3.26279365e-02  6.22155331e-02  2.76114475e-02\n",
      "   1.86883863e-02  3.55805568e-02  4.11795825e-02  1.54782366e-02\n",
      "   4.22691330e-02  3.82248722e-02  1.00313080e-02 -2.83246189e-02\n",
      "   4.47052419e-02 -4.10458818e-02 -4.50554257e-03 -5.44734932e-02\n",
      "   2.62321346e-02  1.79862138e-02 -1.23118818e-01 -4.66952063e-02\n",
      "  -1.35913724e-02  6.46709949e-02  3.57349776e-03 -1.22233536e-02\n",
      "  -1.79381985e-02 -2.55502518e-02  2.37223972e-02  4.08664346e-03\n",
      "  -6.51475638e-02  4.43651788e-02  4.68596183e-02 -3.25174555e-02\n",
      "   4.02271235e-03 -3.97601910e-03  1.11939562e-02 -9.95597988e-02\n",
      "   3.33168209e-02  8.01060125e-02  9.42692086e-02 -6.38294667e-02\n",
      "   3.23151574e-02 -5.13553545e-02 -7.49873416e-03  5.30048403e-34\n",
      "  -4.13194560e-02  9.49646533e-02 -1.06401421e-01  4.96590547e-02\n",
      "  -3.41913477e-02 -3.16745676e-02 -1.71556342e-02  1.70096243e-03\n",
      "   5.79757951e-02 -1.21780997e-03 -1.68536585e-02 -5.16912676e-02\n",
      "   5.52999005e-02 -3.42647806e-02  3.08179203e-02 -3.10481060e-02\n",
      "   9.27532539e-02  3.72663438e-02 -2.37397552e-02  4.45893630e-02\n",
      "   1.46153951e-02  1.16239347e-01 -5.00112735e-02  3.88716273e-02\n",
      "   4.24751732e-03  2.56976094e-02  3.27243581e-02  4.29907702e-02\n",
      "  -1.36144469e-02  2.56122220e-02  1.06262593e-02 -8.46864581e-02\n",
      "  -9.52981934e-02  1.08399823e-01 -7.51600564e-02 -1.37773780e-02\n",
      "   6.37337938e-02 -4.49668523e-03 -3.25321145e-02  6.23613931e-02\n",
      "   3.48053053e-02 -3.54922414e-02 -2.00222153e-02  3.66608314e-02\n",
      "  -2.48837285e-02  1.01818992e-02 -7.01233149e-02 -4.31950800e-02\n",
      "   2.95332558e-02 -2.94986035e-04 -3.45386676e-02  1.46676032e-02\n",
      "  -9.83969793e-02 -4.70488258e-02 -8.85496847e-03 -8.89914632e-02\n",
      "   3.50995809e-02 -1.29602015e-01 -4.98865768e-02 -6.12047240e-02\n",
      "  -5.97797371e-02  9.46317613e-03  4.91217636e-02 -7.75026232e-02\n",
      "   8.09727013e-02 -4.79257628e-02  2.34377827e-03  7.57030845e-02\n",
      "  -2.40176115e-02 -1.52546270e-02  4.86738980e-02 -3.85968648e-02\n",
      "  -7.04831630e-02 -1.20347720e-02 -3.88790220e-02 -7.76016638e-02\n",
      "  -1.07243573e-02  1.04188416e-02 -2.13753860e-02 -9.17386189e-02\n",
      "  -1.11345351e-02 -2.96066329e-02  2.46457979e-02  4.65714652e-03\n",
      "  -1.63449552e-02 -3.95219922e-02  7.73373544e-02 -2.84733418e-02\n",
      "  -3.69934272e-03  8.27665552e-02 -1.10409111e-02  3.13983858e-02\n",
      "   5.35094030e-02  5.75145558e-02 -3.17621976e-02 -1.52911248e-08\n",
      "  -7.99661279e-02 -4.76797223e-02 -8.59788656e-02  5.69616556e-02\n",
      "  -4.08866182e-02  2.23832577e-02 -4.64446051e-03 -3.80130932e-02\n",
      "  -3.10671013e-02 -1.07278619e-02  1.97698772e-02  7.77001446e-03\n",
      "  -6.09472767e-03 -3.86376046e-02  2.80271750e-02  6.78138286e-02\n",
      "  -2.35350709e-02  3.21748033e-02  8.02536774e-03 -2.39107106e-02\n",
      "  -1.21996377e-03  3.14599015e-02 -5.24924211e-02 -8.06813687e-03\n",
      "   3.14770872e-03  5.11496924e-02 -4.44104671e-02  6.36013746e-02\n",
      "   3.85083742e-02  3.30432989e-02 -4.18728031e-03  4.95592915e-02\n",
      "  -5.69604784e-02 -6.49713399e-03 -2.49793660e-02 -1.60867069e-02\n",
      "   6.62288740e-02 -2.06310619e-02  1.08045757e-01  1.68547034e-02\n",
      "   1.43813221e-02 -1.32127199e-02 -1.29387394e-01  6.95216656e-02\n",
      "  -5.55772968e-02 -6.75413609e-02 -5.45815378e-03 -6.13595080e-03\n",
      "   3.90840992e-02 -6.28780052e-02  3.74063365e-02 -1.16570983e-02\n",
      "   1.29150264e-02 -5.52495345e-02  5.16076162e-02 -4.30839928e-03\n",
      "   5.80247417e-02  1.86945237e-02  2.27810405e-02  3.21665779e-02\n",
      "   5.37978858e-02  7.02849254e-02  7.49312043e-02 -8.41774791e-02]]\n"
     ]
    }
   ],
   "source": [
    "### first, testing with SentenceTransformer (opensource)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and merging embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embeddings = initial_dataset['question'].apply(lambda x: model.encode(x))\n",
    "late_embeddings = late_dataset['question'].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiating v1 and v2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data_entries(df1, df2, column):\n",
    "    new_entries = df1[~df1[column].isin(df2[column])]\n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entries = get_new_data_entries(v2_dataset, initial_dataset, column = 'answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entries_embeddings = new_entries['question'].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with OpenAI Embeddings and FAISS indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project into the embedding space\n",
    "embeddings = OpenAIEmbeddings(model=model_embeddings, openai_api_key=openai_api_key)\n",
    "\n",
    "opai_initial_embeddings = embeddings.embed_documents(initial_dataset['answer'])\n",
    "opai_v2_embeddings = embeddings.embed_documents(v2_dataset['answer'])\n",
    "opai_late_embeddings = embeddings.embed_documents(late_dataset['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1536)\n",
      "(15, 1536)\n",
      "(5, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(opai_initial_embeddings))\n",
    "print(np.shape(opai_v2_embeddings))\n",
    "print(np.shape(opai_late_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremented_embeddings = np.vstack([opai_initial_embeddings, opai_late_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(opai_v2_embeddings == incremented_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.143214860143687e-08"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(opai_v2_embeddings - incremented_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0006648267771866926"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(opai_v2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0006648882093352941"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(incremented_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, the difference of a regular embedding value and the subtraction result is in the order of 10000 (exactly -10823.13)\n"
     ]
    }
   ],
   "source": [
    "diff = np.mean(incremented_embeddings)/np.mean(opai_v2_embeddings - incremented_embeddings)\n",
    "print(f\"On average, the proportion between a regular embedding value and the subtraction result is in the order of 10000 (exactly {diff:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it possible to assume the results will be marginally the same of embedding it all again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.317608946381398"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(opai_v2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.319024343085175"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(incremented_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### openai embeddings must be generated prior\n",
    "def merge_openai_embeddings(dataset1, dataset2, embedding):\n",
    "    embeddings_dataset1 = embedding.embed_documents(dataset1)\n",
    "    embeddings_dataset2 = embedding.embed_documents(dataset2)\n",
    "\n",
    "    return np.vstack(embeddings_dataset1, embeddings_dataset2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing in the actual database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql('new_database_dump.sql', con = 'sqlalchemy')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def main(model: str):\n",
    "#     data = await DataExporter.get_langchain_documents()\n",
    "\n",
    "#     llm = model_utils.access_APIs.get_llm(model)\n",
    "#     embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "#     questions_index = {}\n",
    "#     keywords_index = {}\n",
    "#     for db_name, contexts in data.items():\n",
    "#         db = FAISS.from_documents(contexts, embeddings)\n",
    "#         db.save_local(f\"dbs/{db_name}_db/faiss/{EMBEDDING_MODEL}\")\n",
    "\n",
    "#         q_index, kw_index = generate_indexes_from_fragment(contexts, llm)\n",
    "\n",
    "    #     for q, urls in q_index.items():\n",
    "    #         if q not in questions_index:\n",
    "    #             questions_index[q] = []\n",
    "    #         questions_index[q].extend(urls)\n",
    "\n",
    "    #     for k, urls in kw_index.items():\n",
    "    #         if k not in keywords_index:\n",
    "    #             keywords_index[k] = []\n",
    "    #         keywords_index[k].extend(urls)\n",
    "\n",
    "    # op_artifacts_pkg = importlib.resources.files(op_artifacts)\n",
    "    # with open(op_artifacts_pkg.joinpath(\"index_questions.json\"), \"w\") as f:\n",
    "    #     json.dump(questions_index, f, indent=4)\n",
    "    # index_questions = list(questions_index.keys())\n",
    "    # index_questions_embed = np.array(embeddings.embed_documents(index_questions))\n",
    "    # np.savez_compressed(\n",
    "    #     op_artifacts_pkg.joinpath(\"index_questions.npz\"), index_questions_embed\n",
    "    # )\n",
    "\n",
    "    # with open(op_artifacts_pkg.joinpath(\"index_keywords.json\"), \"w\") as f:\n",
    "    #     json.dump(keywords_index, f, indent=4)\n",
    "    # index_keywords = list(keywords_index.keys())\n",
    "    # index_keywords_embed = np.array(embeddings.embed_documents(index_keywords))\n",
    "    # np.savez_compressed(\n",
    "    #     op_artifacts_pkg.joinpath(\"index_keywords.npz\"), index_keywords_embed\n",
    "    # )\n",
    "\n",
    "    # await reorder_file(op_artifacts_pkg.joinpath(\"index_questions.json\"))\n",
    "    # await reorder_file(op_artifacts_pkg.joinpath(\"index_keywords.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_faiss_indexes_same_type(index1, index2):\n",
    "    \n",
    "    # get the vectors from both indexes\n",
    "    _, vectors1 = index1.reconstruct_n(0, index1.ntotal)\n",
    "    _, vectors2 = index2.reconstruct_n(0, index2.ntotal)\n",
    "    \n",
    "    # combine the vectors\n",
    "    all_vectors = np.vstack((vectors1, vectors2))\n",
    "    \n",
    "    # add the combined vectors to a new index\n",
    "    merged_index = faiss.clone_index(index1)\n",
    "    merged_index.add(all_vectors)\n",
    "    \n",
    "    return merged_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_incremental_faiss_update(db_params, new_small_index):\n",
    "\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 1. Get the latest version of the FAISS index from PostgreSQL\n",
    "    cur.execute(\"Query here: get the latest version ordered by timestamp LastEmbeddedAt\") ## todo the query\n",
    "    result = cur.fetchone()\n",
    "    \n",
    "    if result:  # if data inexistent, it will create a new db\n",
    "        latest_index = faiss.deserialize_index(result[0])\n",
    "    else:\n",
    "        latest_index = faiss.IndexFlatL2(new_small_index.d)  \n",
    "\n",
    "    # 2. Merge it with the smaller FAISS index\n",
    "    merged_index = faiss.merge_indexes([latest_index, new_small_index])\n",
    "\n",
    "    # 3. Send the merged FAISS index back to PostgreSQL\n",
    "    merged_index_data = faiss.serialize_index(merged_index)\n",
    "    cur.execute(\"Query here: send the new version ordered by timestamp LastEmbeddedAt\",  ## todo the query\n",
    "                 (psycopg2.Binary(merged_index_data),))\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"FAISS index successfully updated in PostgreSQL.\")\n",
    "\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### async version by Claude\n",
    "\n",
    "async def async_simple_incremental_faiss_update(db_params, new_small_index):\n",
    "    \"\"\"\n",
    "    Asynchronous function to incrementally update a FAISS index stored in PostgreSQL.\n",
    "    \n",
    "    :param db_params: dict, database connection parameters\n",
    "    :param new_small_index: faiss.Index, the new small index to merge\n",
    "    \"\"\"\n",
    "    conn = await asyncpg.connect(**db_params)\n",
    "\n",
    "    try:\n",
    "        # 1. Get the latest version of the FAISS index from PostgreSQL\n",
    "        result = await conn.fetchrow(\"SELECT index_data FROM faiss_index ORDER BY LastEmbeddedAt DESC LIMIT 1\")  ## todo replace query \n",
    "        \n",
    "        if result:\n",
    "            latest_index = faiss.deserialize_index(bytes(result['index_data']))\n",
    "        else:\n",
    "            latest_index = faiss.IndexFlatL2(new_small_index.d)\n",
    "\n",
    "        # 2. Merge it with the smaller FAISS index\n",
    "        merged_index = faiss.merge_indexes([latest_index, new_small_index])\n",
    "\n",
    "        # 3. Send the merged FAISS index back to PostgreSQL\n",
    "        merged_index_data = faiss.serialize_index(merged_index)\n",
    "        await conn.execute(\n",
    "            \"Query here\",                 ## todo\n",
    "            merged_index_data\n",
    "        )\n",
    "\n",
    "        print(\"FAISS index successfully updated in PostgreSQL.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        await conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleu-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
