{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for exploring variations on LLM, embeddings, RAG arch and prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBs that are going to be retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = [\n",
    "    \"full_docs\",\n",
    "    \"fragments_docs\",\n",
    "    \"posts_forum\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options of embedding, chat and vectorscore to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to test the open ai api for embeddings\n",
    "embedding_models = [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]\n",
    "\n",
    "# we are going to test the open ai api for chat\n",
    "chat_models = [\"gpt-3.5-turbo-0125\", \"gpt-3.5-turbo-instruct\", \"gpt-4o\", \"gpt-4o-2024-05-13\"]\n",
    "\n",
    "# we are going to use faiss\n",
    "vectorstores = ['faiss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "\n",
    "# embedding and chat\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# openai api key\n",
    "openai_api_key = getpass(\"Enter the OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# vectorstore\n",
    "if 'faiss' in vectorstores:\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# for tracking\n",
    "import weave\n",
    "from weave import Evaluation\n",
    "\n",
    "# the metrics\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['How can I get involved in the Optimism Collective?',\n",
       "  'Can Optimism currently censor user transactions?',\n",
       "  'Who are the members of the proposed Decentralized Finance Governance Committee for Optimism?',\n",
       "  'What were some of the outcomes and feedback from Season 3 of the Grants Council?',\n",
       "  \"Why is there a 'no-sale' rule for growth experiments?\",\n",
       "  'What kind of activities can the Optimism Foundation perform due to its legal status?',\n",
       "  'What types of contributions are eligible for RetroPGF?',\n",
       "  'Where can I see applications for voting on Retro Funding?',\n",
       "  'Do I need to claim my tokens for Airdrop #2?',\n",
       "  'What are the main governance structures introduced in Season 5?',\n",
       "  'How does a non-grant proposal proceed to a vote in the Optimism Governance Forum?',\n",
       "  'What were some of the key activities and contributions of Women Biz to the Optimism ecosystem?',\n",
       "  'Who can join alliances and participate in missions?',\n",
       "  \"What will happen after the Working Constitution's period ends?\",\n",
       "  'What are Retroactive Public Goods Funding (RetroPGF) rounds?',\n",
       "  'What is the action plan if a critical security issue is discovered before the MCP L1 upgrade is deployed?',\n",
       "  \"What should I do if I find a bug that is not covered by Optimism's existing bug bounty programs?\",\n",
       "  'How are the rubrics for reviewing Mission applications in Season 5 structured?',\n",
       "  'How is the scope and voting process for Retro Funding determined?',\n",
       "  'What concerns did jackanorak express about some of the missions under Intent 3?',\n",
       "  'How can limiting delegate voting power promote decentralization and new delegate inclusion?',\n",
       "  'How can I claim my Airdrop #4 rewards?',\n",
       "  'What are the key milestones Giveth aims to achieve with the Optimism grant?',\n",
       "  \"How can I promote my project once it's deployed on the Superchain?\",\n",
       "  'What should I do if I am a Top 100 delegate and want to approve a non-grant proposal?',\n",
       "  'What is the trend observed in the types of proposals received in Cycle 15?',\n",
       "  'Do I need to hold a minimum amount of tokens to submit a proposal?',\n",
       "  'How were the badgeholders for RetroPGF Round 2 selected?',\n",
       "  'What are some proposed solutions to address the issue of popularity bias and nepotism in the RetroPGF voting process?',\n",
       "  'What is the main purpose of the Optimism Foundation?',\n",
       "  'What are the key timelines for RetroPGF round 2?',\n",
       "  'When will the Citizens’ House veto vote take place?',\n",
       "  'How can I get test tokens on the OP Goerli network?',\n",
       "  'How does the Pairwise voting system work in the context of RetroPGF?',\n",
       "  'How can I become a support NERD in the Optimism community?',\n",
       "  'What changes are being considered to improve the Mission proposal process?',\n",
       "  'What are the benefits of using Reputation-based Weighted Voting in DAO decision-making?',\n",
       "  'What tools from the Optimism community are integrated into the bootcamp?',\n",
       "  'What idea was proposed regarding the vote threshold for different amounts of OP requested?',\n",
       "  'Why should I delegate my OP tokens?',\n",
       "  'How will the committee make its recommendations?',\n",
       "  'What are the potential risks and safeguards associated with the fault proof system?',\n",
       "  'What are the main features introduced by the Ecotone network upgrade?',\n",
       "  'How are users currently finding unread posts in the redesigned forum?',\n",
       "  'What suggestions were made to improve the voting process?',\n",
       "  'How long do I need to offer support before becoming a `support-NERD`?',\n",
       "  'Who is Cryptoversidad and what is their mission?',\n",
       "  'How do I apply for a Mission Grant on Optimism?',\n",
       "  'What new features has Karma introduced to improve delegate onboarding and management?',\n",
       "  \"What are the main security properties that any voting system must have according to Vitalik's blog post?\"],\n",
       " 'ground_truth': ['You can get involved in the Optimism Collective by following three principles: do what you love, fix problems together, and do it with optimism. There are various ways to contribute, such as helping with translations, improving documentation, participating in local events, or joining support programs like the NERD program.',\n",
       "  \"No, even though the Optimism Foundation currently runs the sole sequencer on OP Mainnet, it does not have the ability to censor user transactions. However, decentralizing the sequencer is still a goal to further enhance the network's robustness and inclusivity.\",\n",
       "  'The committee consists of Katie Garcia, GFX Labs, Flipside Crypto, StableNode, and Linda Xie.',\n",
       "  'Season 3 saw the review of over 150 proposals, with feedback indicating a significant improvement in the grants process. The Council received an NPS of 9.2 out of 10 from successful proposers, highlighting its emphasis on transparency and efficiency.',\n",
       "  \"The 'no-sale' rule for growth experiments ensures that grants are used to drive consumer interactions and usage of applications on Optimism, rather than being sold by the protocol that receives them. This rule makes it explicit that the grants should be distributed to drive consumer usage in line with the experiment outlined in the grant.\",\n",
       "  'The Optimism Foundation can enter into contracts with third parties, administer intellectual property rights, and make required governmental reports and filings.',\n",
       "  \"Every type of contribution to the Optimism ecosystem is eligible for Retro Funding. This includes developers working on Ethereum execution clients, educators creating Optimism-inspired content, artists, creators, writers, builders, and evangelists. Essentially, if you're providing impact to the Optimism Collective, you're eligible.\",\n",
       "  'You can see applications on the voting applications from Agora and West. The links are [Agora](https://vote.optimism.io/retropgf/3) and [West](https://round3.optimism.io/).',\n",
       "  'No, Airdrop #2 tokens are distributed directly to eligible wallets. There is no need to claim tokens by interacting with any website.',\n",
       "  \"Season 5 introduces several governance structures including the Security Council, Developer Advisory Board, Anticapture Commission, Grants Council, and Code of Conduct Councils, each with specific roles and responsibilities to support the Collective's goals.\",\n",
       "  'For a non-grant proposal to proceed to a vote, four of the top 100 delegates, based on the current votable token supply, must give explicit approval on the discussion thread. Delegates may not approve their own proposals.',\n",
       "  'Women Biz organized numerous events, workshops, and tours throughout Peru, teaching how to mint NFTs, POAPs, delegate votes, and more. They also created content on platforms like Mirror.xyz, conducted interviews, and promoted Optimism through various channels.',\n",
       "  'Anyone can join or form an alliance, which can be a single person, a group of contributors, or even an incorporated entity.',\n",
       "  \"After the Working Constitution's period ends, authority over governance will be ceded to a permanent Bedrock Constitution that incorporates the lessons learned from the Collective’s prior governance experiments.\",\n",
       "  'Retroactive Public Goods Funding (RetroPGF) rounds are quarterly events where Optimism rewards public goods based on their impact on the ecosystem. This funding is sourced from the initial OP token supply and network revenues. The goal is to ensure that impactful projects are adequately and reliably rewarded.',\n",
       "  'If a critical security issue is discovered, OP Labs will collaborate with the community to extensively communicate that the upgrade will no longer occur.',\n",
       "  \"If you find a critical or major bug that is not covered by Optimism's existing bug bounty programs, you should still report it via the Immunefi program. Optimism will seriously consider the impact of any issues and has previously rewarded security researchers for bugs not within the stated scope of the program.\",\n",
       "  'The rubrics are standardized for each intent and subcommittee, with optional categories that can be removed if not applicable to a specific mission request. They are designed to guide reviewers in evaluating applications consistently.',\n",
       "  'During the initial stages, the Optimism Foundation determines the scope and amount of each funding round and administers the voting process. Over time, the Citizens’ House will take on more responsibility for these decisions, with checks and balances from the Token House. The process involves regular rounds of funding, each different from the last, to refine tools and processes based on community participation and experimentation.',\n",
       "  'Jackanorak expressed concerns that some missions appeared as outright giveaways relative to the value they would create and emphasized the need to consider competition and the broader vision of Optimism in governance decisions.',\n",
       "  'Limiting delegate voting power can prevent centralization by ensuring that no single delegate has excessive influence. This encourages token holders to redelegate their tokens to other delegates, promoting a more diverse and active community.',\n",
       "  'You can claim your Airdrop #4 rewards by visiting [https://app.optimism.io/airdrops](https://app.optimism.io/airdrops).',\n",
       "  'The key milestones include enabling projects to add an Optimism donation address, launching GIVpower and GIVbacks on Optimism, and achieving significant user engagement metrics such as 100 donors of over $10, 30+ projects receiving donations, $100k in donations to verified projects, and 1M GIV staked for GIVpower.',\n",
       "  \"Once your project is deployed on the Superchain, you can be added to the Superchain apps page by filling out a specific form. To amplify your app launch through Superchain marketing channels, you can fill out another form. Keep in mind that inclusion and amplification are at Optimism's discretion.\",\n",
       "  \"If you are a Top 100 delegate, you can approve non-grant proposals by posting the phrase 'I am an Optimism delegate with sufficient voting power and I believe this proposal is ready to move to a vote' in a forum comment on Discourse. Non-grant proposals need at least 4 approvals to move to a vote.\",\n",
       "  'Cycle 15 saw more Builders proposals than Experiments proposals, indicating a focus on innovating novel applications.',\n",
       "  'No, there is no minimum holding requirement for submitting a proposal. However, all non-grant proposals must be approved by four delegates with sufficient voting power to move to a vote.',\n",
       "  'Badgeholders for RetroPGF Round 2 were selected through four different criteria: 14 were chosen based on their participation in the first round, 21 were selected by the Optimism Foundation, 10 were elected by Optimism’s Token House, and 29 were nominated by badgeholders from the previous three categories.',\n",
       "  'One solution is to require badgeholders to review entire categories of projects rather than individual projects, ensuring smaller projects get fair evaluations.',\n",
       "  'The main purpose of the Optimism Foundation is to support the establishment of the Optimism Collective, develop the Optimism ecosystem, and advance the technology that powers it. It also provides a formal legal entity to support the Collective and stewards the early evolution of Collective governance.',\n",
       "  'Project nominations are from Jan 17 to Jan 31, the final project opt-in deadline is Feb 21, and voting takes place from Mar 7 to Mar 21.',\n",
       "  'The Citizens’ House veto vote will take place via Snapshot from June 20th to June 26th.',\n",
       "  'You can obtain test tokens, including ETH, ERC-20, and NFT tokens, from faucets. You can find more information on how to access these faucets [here](../useful-tools/faucets.md).',\n",
       "  'Pairwise is an open-source, off-chain voting dapp that simplifies community signaling by allowing users to select between two options and aggregating their choices into a quantifiable result. It aims to be user-friendly and intuitive, converting subjective inputs into objective, measurable outputs.',\n",
       "  \"To become a support NERD, you need to follow a few steps. First, you start as a 'wannabe-NERD' by filling out a form and being active in the Optimism Discord for at least two months. Then, you move to 'NERD-in-training' by proving your contributions and continuing to offer support for an additional two months. Finally, if your support is of high quality, you can be nominated and voted on by existing support NERDs to become a full 'support-NERD'.\",\n",
       "  'Changes being considered include separating the Council and Mission processes, redesigning the approval process to allow delegates to opt-in for specific Intents, and improving the accessibility of the system through better templates, guides, and workshops.',\n",
       "  'RWV encourages voters to become experts in their domain, establishes incentives for decision-makers, and grants voting power to those actively involved in good decisions, making the process transparent and robust.',\n",
       "  'The bootcamp integrates tools such as Mirror, Praise, 1inch, Charmverse, Thirdweb3, Unlockprotocol, and Zora.',\n",
       "  'It was proposed to have a scaling vote threshold for the amount of OP requested, meaning larger grants (e.g., 4 million OP) should require more buy-in than smaller grants (e.g., 100k OP).',\n",
       "  'Delegating your OP tokens allows you to participate in the governance of the Optimism Token House without needing to commit a lot of time. You can delegate your voting power to a community member who has volunteered to be an active participant in governance. This way, your interests are represented without you having to vote on every issue yourself.',\n",
       "  'The committee will provide basic due diligence research, a brief summary, and a voting recommendation for each proposal related to borrow/lend protocols, decentralized exchanges, yield aggregators, decentralized stablecoins, and other DeFi-related proposals. Recommendations will be decided by a simple majority vote.',\n",
       "  'The potential risks include the possibility of bugs in the Fault Dispute Game, which could require proactive intervention by the Guardian role to prevent invalid withdrawals. Safeguards include off-chain monitoring, a delay before withdrawals can occur, and the ability for the Guardian to blacklist dispute games or revert to a permissioned system.',\n",
       "  'The main features include EIP-4844 blobs for data availability, Dencun L1 extensions, new opcodes, and beacon root support.',\n",
       "  \"Users are currently going to the 'latest' tab to find unread posts.\",\n",
       "  'Suggestions include having a break between voting cycles to allow more time for review, creating a committee to enforce rules and maintain standards, and being more optimistic and less risk-averse in evaluating proposals to help kickstart the ecosystem.',\n",
       "  'You need to offer support for a total of five months before becoming a `support-NERD`. Initially, you need to offer support for three months to get the `nerd-in-training` role. Then, you need to continue offering support for an additional two months while holding the `nerd-in-training` role.',\n",
       "  'Cryptoversidad is an educational platform that focuses on teaching and using web3 technology. Their mission is to make web3 easy to understand and use through university education, explainer videos, tutorials, workshops, and in-person events.',\n",
       "  'To apply for a Mission Grant, find an open Mission Request on the list provided on their GitHub, submit your application via the application link or as a comment on the GitHub Issue, and your application will be evaluated by the Grants Council or the Optimism Foundation.',\n",
       "  'Karma introduced features like an onboarding flow for delegates to update their pitch and skills, the ability to withdraw nominations, linking social handles, and marking inactive delegates.',\n",
       "  'The main security properties are correct execution, censorship resistance, privacy, and coercion resistance.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = \"../002_create_test_dataset/questions_test_dataset.csv\"\n",
    "test_dataset = pd.read_csv(test_path)\n",
    "\n",
    "# drop origin\n",
    "test_dataset = test_dataset.drop(columns=['origin'])\n",
    "\n",
    "# change columns\n",
    "test_dataset = test_dataset.rename(columns={'answer': 'ground_truth'})\n",
    "\n",
    "# sample 50 questions\n",
    "test_dataset = test_dataset.sample(50, random_state=42)\n",
    "\n",
    "# as dict\n",
    "test_dataset = test_dataset.to_dict(orient='list')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General definitions for accessing data and creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(dbs, model_embeddings, vectorstore = 'faiss'):\n",
    "    embeddings = OpenAIEmbeddings(model=model_embeddings, openai_api_key=openai_api_key)\n",
    "    if vectorstore == 'faiss':\n",
    "        dbs = [f\"dbs/{name}_db/faiss/{model_embeddings}\" for name in dbs]\n",
    "        dbs = [FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True) for db_path in dbs]\n",
    "        db = dbs[0]\n",
    "        for db_ in dbs[1:]:\n",
    "            db.merge_from(db_)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGModel():\n",
    "    @weave.op()\n",
    "    def __init__(self, dbs, model_embeddings, chat_pars, prompt_template, vectorstore = 'faiss'):\n",
    "        self.dbs_name = dbs\n",
    "        self.embeddings_name = model_embeddings\n",
    "        self.vectorstore_name = vectorstore\n",
    "\n",
    "        self.db = load_db(dbs, model_embeddings, vectorstore)\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        llm = ChatOpenAI(**chat_pars, openai_api_key=openai_api_key)\n",
    "        self.chain = prompt | llm\n",
    "    \n",
    "    @weave.op()\n",
    "    def find_similar_docs(self, query, **retriever_kwargs):\n",
    "        if self.vectorstore_name == 'faiss':\n",
    "            retriever = self.db.as_retriever(**retriever_kwargs)\n",
    "            return retriever.invoke(query)\n",
    "        \n",
    "    @weave.op()\n",
    "    def get_answer(self, question: str, retriever_kwargs={}):\n",
    "        context = self.find_similar_docs(question, **retriever_kwargs)\n",
    "\n",
    "        response = self.chain.invoke(\n",
    "            {\n",
    "                \"context\": context,\n",
    "                \"question\": question,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return context, response\n",
    "    \n",
    "    def ask(self, question: str, retriever_kwargs={}):\n",
    "        context, response = self.get_answer(question, retriever_kwargs)\n",
    "        return response.content\n",
    "    \n",
    "    def evaluate_on(self, test_dataset, retriever_kwargs={}):\n",
    "        answers = []\n",
    "        contexts = []\n",
    "        for q in test_dataset['question']:\n",
    "            context, response = self.get_answer(q, retriever_kwargs)\n",
    "            answers.append(response.content)\n",
    "            contexts.append([c.page_content for c in context])\n",
    "\n",
    "        test_data = test_dataset.copy()\n",
    "        test_data['contexts'] = contexts\n",
    "        test_data['answer'] = answers\n",
    "        return evaluate(\n",
    "            Dataset.from_dict(test_data)\n",
    "        )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  26%|██▌       | 51/200 [03:07<09:09,  3.69s/it]\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/executor.py\", line 95, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/executor.py\", line 83, in _aresults\n",
      "    raise e\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/executor.py\", line 78, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/asyncio/tasks.py\", line 631, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/executor.py\", line 111, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/metrics/base.py\", line 125, in ascore\n",
      "    raise e\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/metrics/base.py\", line 121, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/__init__.py\", line 410, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/__init__.py\", line 183, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 569, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 657, in _agenerate\n",
      "    response = await self.async_client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1214, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1790, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1493, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1569, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1615, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/victor/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-m0dRk26O0RxgztiyYyN5RCBO on tokens per min (TPM): Limit 80000, Used 78429, Requested 6080. Please try again in 3.381s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m rag \u001b[38;5;241m=\u001b[39m RAGModel(\n\u001b[1;32m     20\u001b[0m     dbs \u001b[38;5;241m=\u001b[39m [dbs[\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m     21\u001b[0m     model_embeddings \u001b[38;5;241m=\u001b[39m embedding_models[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     22\u001b[0m     chat_pars\u001b[38;5;241m=\u001b[39mchat_pars,\n\u001b[1;32m     23\u001b[0m     prompt_template \u001b[38;5;241m=\u001b[39m prompt_template\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#rag.ask(\"what is optimism?\")\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_on\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mRAGModel.evaluate_on\u001b[0;34m(self, test_dataset, retriever_kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m contexts\n\u001b[1;32m     47\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m answers\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/evaluation.py:250\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_group_cm\u001b[38;5;241m.\u001b[39mended:\n\u001b[1;32m    248\u001b[0m         evaluation_rm\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     result \u001b[38;5;241m=\u001b[39m Result(\n\u001b[1;32m    253\u001b[0m         scores\u001b[38;5;241m=\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_list(scores),\n\u001b[1;32m    254\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    255\u001b[0m         binary_columns\u001b[38;5;241m=\u001b[39mbinary_metrics,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bleu-chatbot/lib/python3.12/site-packages/ragas/evaluation.py:232\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    230\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# convert results to dataset_like\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "#weave.init('first-test')\n",
    "chat_pars = {\n",
    "    \"model\": chat_models[0],\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": None,\n",
    "    \"timeout\": None,\n",
    "    \"max_retries\": 2\n",
    "}\n",
    "\n",
    "prompt_template = f\"\"\"Answer politely the question at the end, using only the following context. The user is not necessarily a specialist, so please avoid jargon and explain any technical terms.\n",
    "\n",
    "<context>\n",
    "{{context}} \n",
    "</context>\n",
    "\n",
    "Question: {{question}}\n",
    "\"\"\"\n",
    "\n",
    "rag = RAGModel(\n",
    "    dbs = [dbs[0]],\n",
    "    model_embeddings = embedding_models[0],\n",
    "    chat_pars=chat_pars,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "\n",
    "#rag.ask(\"what is optimism?\")\n",
    "\n",
    "rag.evaluate_on(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question = test_dataset[\\'question\\'][0]\\nground_truth = test_dataset[\\'ground_truth\\'][0]\\n\\nexamples = [\\n    {\\n        \"question\": question,\\n        \"ground_truth\": ground_truth\\n    }\\n\\n]\\n\\n# Define any custom scoring function\\n@weave.op()\\ndef score(question: str, model_output):\\n    contexts, answer = model_output[\"contexts\"], model_output[\"answer\"]\\n    print(model_output)\\n    test_data = Dataset.from_dict({\\n        \"question\": [question],\\n        \"contexts\": [contexts],\\n        \"answer\": [answer],\\n        \"ground_truth\": [ground_truth]\\n    })\\n\\n    return evaluate(\\n        test_data,\\n        raise_exceptions=False\\n    )\\n\\n@weave.op()\\ndef function_to_evaluate(question: str):\\n    context, answer = rag.get_answer(question)\\n    context = [c.page_content for c in context]\\n    answer = answer.content\\n\\n    return {\"answer\": answer, \"contexts\": context}\\n\\n# Score your examples using scoring functions\\nevaluation = Evaluation(\\n    dataset=examples, scorers=[score]\\n)\\n\\n# Start tracking the evaluation\\n# Run the evaluation\\nawait evaluation.evaluate(function_to_evaluate)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"question = test_dataset['question'][0]\n",
    "ground_truth = test_dataset['ground_truth'][0]\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": question,\n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "# Define any custom scoring function\n",
    "@weave.op()\n",
    "def score(question: str, model_output):\n",
    "    contexts, answer = model_output[\"contexts\"], model_output[\"answer\"]\n",
    "    print(model_output)\n",
    "    test_data = Dataset.from_dict({\n",
    "        \"question\": [question],\n",
    "        \"contexts\": [contexts],\n",
    "        \"answer\": [answer],\n",
    "        \"ground_truth\": [ground_truth]\n",
    "    })\n",
    "\n",
    "    return evaluate(\n",
    "        test_data,\n",
    "        raise_exceptions=False\n",
    "    )\n",
    "\n",
    "@weave.op()\n",
    "def function_to_evaluate(question: str):\n",
    "    context, answer = rag.get_answer(question)\n",
    "    context = [c.page_content for c in context]\n",
    "    answer = answer.content\n",
    "\n",
    "    return {\"answer\": answer, \"contexts\": context}\n",
    "\n",
    "# Score your examples using scoring functions\n",
    "evaluation = Evaluation(\n",
    "    dataset=examples, scorers=[score]\n",
    ")\n",
    "\n",
    "# Start tracking the evaluation\n",
    "# Run the evaluation\n",
    "await evaluation.evaluate(function_to_evaluate)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleu-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
